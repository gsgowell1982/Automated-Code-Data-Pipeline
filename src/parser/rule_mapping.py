#!/usr/bin/env python3
"""
Rule Mapping Generator - DBR-01: Authentication & Credential Integrity

This module reads the AST analysis JSON file generated by fast_api_analyzer.py
and maps the code evidence to the DBR-01 rule metadata.

DBR-01 Rule Description:
身份准入与账户凭据完整性（Authentication & Credential Integrity）

Business Logic:
1. Multi-scenario uniqueness interception (Sign-up & Update)
2. Account security and storage atomicity 
3. Authentication security feedback (Login)
4. Dynamic session state maintenance (Token Refresh)

Output Schema Compatibility:
This module generates metadata compatible with downstream Q&A generation schema:
- sample_id: Auto-generated unique ID
- instruction: Auto-generated question
- context: {file_path, related_dbr, code_snippet}
- auto_processing: {parser, dbr_logic, data_cleaning}
- reasoning_trace: List of structured reasoning steps
- answer: Gold standard answer
- data_quality: {consistency_check, language, temperature}

Author: Auto-generated
Version: 2.0.0
"""

import json
import os
import hashlib
import logging
import uuid
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Optional, Any, Set, Tuple
from enum import Enum

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Version info
RULE_MAPPING_VERSION = "2.0.0"
PARSER_NAME = "FastAPI-AST-Analyzer"
PARSER_VERSION = "1.0.0"


class EvidenceType(str, Enum):
    """Types of code evidence for rule mapping."""
    FUNCTION = "function"
    VARIABLE = "variable"
    EXCEPTION_HANDLING = "exception_handling"
    CALL = "call"
    IMPORT = "import"
    PATTERN = "pattern"


class TriggerType(str, Enum):
    """Types of DBR rule triggers."""
    EXPLICIT = "explicit"  # Direct code pattern match
    IMPLICIT = "implicit"  # Inferred from context
    COMPOSITE = "composite"  # Multiple patterns combined


@dataclass
class CodeLocation:
    """Location information for code evidence."""
    file_path: str
    module_name: str
    line_start: int
    line_end: int
    qualified_name: Optional[str] = None


@dataclass
class CodeSnippet:
    """Actual source code snippet with metadata."""
    code: str
    language: str = "python"
    line_start: int = 0
    line_end: int = 0
    file_path: str = ""
    source_hash: str = ""  # MD5 hash for consistency check
    
    def compute_hash(self) -> str:
        """Compute MD5 hash of the code snippet."""
        self.source_hash = hashlib.md5(self.code.encode('utf-8')).hexdigest()
        return self.source_hash


@dataclass
class DBRLogic:
    """DBR rule logic with weight and trigger information."""
    rule_id: str
    subcategory_id: str
    trigger_type: TriggerType
    weight: float = 1.0  # Importance weight (0.0 - 1.0)
    trigger_conditions: List[str] = field(default_factory=list)
    matched_patterns: List[str] = field(default_factory=list)


@dataclass
class ReasoningStep:
    """A single step in the reasoning trace."""
    step_id: int
    step_type: str  # "observation", "analysis", "inference", "conclusion"
    description: str
    description_cn: str
    source_reference: Optional[str] = None  # Reference to code location
    dbr_reference: Optional[str] = None  # Reference to DBR rule


@dataclass
class ReasoningTemplate:
    """Template for generating reasoning traces."""
    template_id: str
    template_name: str
    steps: List[ReasoningStep] = field(default_factory=list)
    applicable_to: List[str] = field(default_factory=list)  # List of evidence_ids


@dataclass
class CodeEvidence:
    """Evidence of a rule implementation in code."""
    evidence_id: str
    evidence_type: EvidenceType
    name: str
    description: str
    description_cn: str
    location: CodeLocation
    # New fields for Q&A schema compatibility
    code_snippet: Optional[CodeSnippet] = None
    dbr_logic: Optional[DBRLogic] = None
    reasoning_template: Optional[ReasoningTemplate] = None
    related_elements: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RuleSubCategory:
    """Sub-category of a rule with specific code evidence."""
    subcategory_id: str
    name: str
    name_cn: str
    description: str
    description_cn: str
    evidences: List[CodeEvidence] = field(default_factory=list)
    # New fields for Q&A generation
    question_templates: List[str] = field(default_factory=list)  # Templates for generating questions
    question_templates_cn: List[str] = field(default_factory=list)


@dataclass
class ParserInfo:
    """Information about the static analysis parser used."""
    name: str
    version: str
    analysis_timestamp: str
    source_file: str
    capabilities: List[str] = field(default_factory=list)


@dataclass
class DataCleaningInfo:
    """Information about data cleaning and desensitization."""
    cleaned: bool = True
    desensitized: bool = False
    cleaning_rules: List[str] = field(default_factory=list)
    excluded_patterns: List[str] = field(default_factory=list)


@dataclass
class QAGenerationConfig:
    """Configuration for Q&A pair generation."""
    default_language: str = "en"
    supported_languages: List[str] = field(default_factory=lambda: ["en", "zh"])
    default_temperature: float = 0.7
    include_code_snippets: bool = True
    include_reasoning_trace: bool = True
    max_snippet_lines: int = 50


@dataclass
class RuleMetadata:
    """Complete metadata for a design rule."""
    rule_id: str
    rule_name: str
    rule_name_cn: str
    description: str
    description_cn: str
    version: str
    created_at: str
    analysis_source: str
    project_name: str
    subcategories: List[RuleSubCategory] = field(default_factory=list)
    related_files: List[str] = field(default_factory=list)
    related_functions: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    tags: List[str] = field(default_factory=list)
    # New fields for Q&A schema compatibility
    parser_info: Optional[ParserInfo] = None
    data_cleaning: Optional[DataCleaningInfo] = None
    qa_config: Optional[QAGenerationConfig] = None
    reasoning_templates: List[ReasoningTemplate] = field(default_factory=list)
    source_code_root: str = ""  # Root path for source code extraction


class DBR01RuleMapper:
    """
    Mapper for DBR-01: Authentication & Credential Integrity rule.
    
    This class extracts code evidence from the AST analysis JSON and maps
    it to the structured DBR-01 rule metadata.
    
    Compatible with downstream Q&A generation schema.
    """
    
    RULE_ID = "DBR-01"
    RULE_NAME = "Authentication & Credential Integrity"
    RULE_NAME_CN = "身份准入与账户凭据完整性"
    
    # Target functions for rule mapping
    TARGET_FUNCTIONS = {
        "login": "app.api.routes.authentication.login",
        "register": "app.api.routes.authentication.register",
        "retrieve_current_user": "app.api.routes.users.retrieve_current_user",
        "update_current_user": "app.api.routes.users.update_current_user",
    }
    
    # Service functions
    SERVICE_FUNCTIONS = {
        "check_username_is_taken": "app.services.authentication.check_username_is_taken",
        "check_email_is_taken": "app.services.authentication.check_email_is_taken",
        "create_access_token_for_user": "app.services.jwt.create_access_token_for_user",
    }
    
    # Repository methods
    REPOSITORY_METHODS = {
        "create_user": "app.db.repositories.users.UsersRepository.create_user",
        "update_user": "app.db.repositories.users.UsersRepository.update_user",
        "get_user_by_email": "app.db.repositories.users.UsersRepository.get_user_by_email",
        "get_user_by_username": "app.db.repositories.users.UsersRepository.get_user_by_username",
    }
    
    # Key variables to track
    KEY_VARIABLES = {
        "wrong_login_error",
        "user_create",
        "user_update",
        "current_user",
        "token",
        "existence_error",
    }
    
    # Key imports
    KEY_IMPORTS = {
        "EntityDoesNotExist",
        "HTTP_400_BAD_REQUEST",
        "HTTPException",
        "UsersRepository",
        "UserWithToken",
    }
    
    # Question templates for Q&A generation
    QUESTION_TEMPLATES = {
        "DBR-01-01": [
            "How does the system handle username/email uniqueness during registration?",
            "What happens when a user tries to register with an existing email?",
            "Explain the conditional update validation logic for user profile updates.",
        ],
        "DBR-01-01-CN": [
            "系统如何在注册时处理用户名/邮箱的唯一性检查？",
            "当用户使用已存在的邮箱注册时会发生什么？",
            "解释用户资料更新时的条件验证逻辑。",
        ],
        "DBR-01-02": [
            "How does the system ensure atomicity during user account creation?",
            "Describe the password hashing mechanism in user registration.",
        ],
        "DBR-01-02-CN": [
            "系统如何确保用户账户创建时的原子性？",
            "描述用户注册时的密码哈希机制。",
        ],
        "DBR-01-03": [
            "How does the login function prevent user enumeration attacks?",
            "What error message is returned for failed login attempts and why?",
        ],
        "DBR-01-03-CN": [
            "登录函数如何防止用户枚举攻击？",
            "登录失败时返回什么错误信息？为什么？",
        ],
        "DBR-01-04": [
            "When and how is the JWT token refreshed in the system?",
            "Which API endpoints return a new JWT token to the client?",
        ],
        "DBR-01-04-CN": [
            "系统何时以及如何刷新JWT令牌？",
            "哪些API端点会向客户端返回新的JWT令牌？",
        ],
    }

    def __init__(self, analysis_json_path: str, source_root: Optional[str] = None):
        """
        Initialize the rule mapper.
        
        Args:
            analysis_json_path: Path to the AST analysis JSON file
            source_root: Root path for source code extraction (optional)
        """
        self.analysis_json_path = Path(analysis_json_path)
        self.analysis_data: Dict[str, Any] = {}
        self.modules_by_path: Dict[str, Dict] = {}
        self.modules_by_name: Dict[str, Dict] = {}
        self.functions_by_name: Dict[str, Dict] = {}
        self.classes_by_name: Dict[str, Dict] = {}
        self.source_root: Optional[Path] = Path(source_root) if source_root else None
        self._source_cache: Dict[str, List[str]] = {}  # Cache for source file contents
        
    def load_analysis(self) -> bool:
        """Load and parse the analysis JSON file."""
        if not self.analysis_json_path.exists():
            logger.error(f"Analysis file not found: {self.analysis_json_path}")
            return False
            
        try:
            with open(self.analysis_json_path, 'r', encoding='utf-8') as f:
                self.analysis_data = json.load(f)
            logger.info(f"Loaded analysis from: {self.analysis_json_path}")
            
            # Set source root from analysis data if not provided
            if self.source_root is None:
                root_path = self.analysis_data.get("root_path", "")
                if root_path:
                    self.source_root = Path(root_path)
            
            # Index modules for quick lookup
            self._index_modules()
            return True
            
        except Exception as e:
            logger.error(f"Error loading analysis JSON: {e}")
            return False
    
    def _read_source_file(self, file_path: str) -> List[str]:
        """Read source file and cache its contents."""
        if file_path in self._source_cache:
            return self._source_cache[file_path]
        
        if self.source_root is None:
            return []
        
        full_path = self.source_root / file_path
        if not full_path.exists():
            logger.warning(f"Source file not found: {full_path}")
            return []
        
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            self._source_cache[file_path] = lines
            return lines
        except Exception as e:
            logger.error(f"Error reading source file {full_path}: {e}")
            return []
    
    def _extract_code_snippet(
        self, 
        file_path: str, 
        line_start: int, 
        line_end: int,
        max_lines: int = 50
    ) -> Optional[CodeSnippet]:
        """Extract actual source code snippet from file."""
        lines = self._read_source_file(file_path)
        if not lines:
            return None
        
        # Adjust line numbers (1-indexed to 0-indexed)
        start_idx = max(0, line_start - 1)
        end_idx = min(len(lines), line_end)
        
        # Limit snippet size
        if end_idx - start_idx > max_lines:
            end_idx = start_idx + max_lines
        
        code_lines = lines[start_idx:end_idx]
        code = ''.join(code_lines)
        
        snippet = CodeSnippet(
            code=code,
            language="python",
            line_start=line_start,
            line_end=min(line_end, start_idx + max_lines + 1),
            file_path=file_path,
        )
        snippet.compute_hash()
        
        return snippet
    
    def _create_dbr_logic(
        self,
        subcategory_id: str,
        trigger_type: TriggerType,
        weight: float,
        trigger_conditions: List[str],
        matched_patterns: List[str]
    ) -> DBRLogic:
        """Create DBR logic metadata for an evidence."""
        return DBRLogic(
            rule_id=self.RULE_ID,
            subcategory_id=subcategory_id,
            trigger_type=trigger_type,
            weight=weight,
            trigger_conditions=trigger_conditions,
            matched_patterns=matched_patterns,
        )
    
    def _create_reasoning_template(
        self,
        template_id: str,
        template_name: str,
        evidence_type: str,
        key_elements: List[str],
        applicable_to: List[str]
    ) -> ReasoningTemplate:
        """Create a reasoning template for an evidence type."""
        steps = []
        
        # Generate standard reasoning steps based on evidence type
        if evidence_type == "exception_handling":
            steps = [
                ReasoningStep(
                    step_id=1,
                    step_type="observation",
                    description="Identify the exception handling structure in the function",
                    description_cn="识别函数中的异常处理结构",
                    source_reference="try-except block",
                ),
                ReasoningStep(
                    step_id=2,
                    step_type="analysis",
                    description=f"Analyze the predefined error variable and its usage",
                    description_cn="分析预定义的错误变量及其使用方式",
                    source_reference=", ".join(key_elements[:2]) if key_elements else None,
                ),
                ReasoningStep(
                    step_id=3,
                    step_type="inference",
                    description="Determine how the unified error response prevents information leakage",
                    description_cn="判断统一的错误响应如何防止信息泄露",
                    dbr_reference=f"{self.RULE_ID}-03",
                ),
                ReasoningStep(
                    step_id=4,
                    step_type="conclusion",
                    description="Conclude the security benefit of vague error messages",
                    description_cn="总结模糊错误信息的安全收益",
                ),
            ]
        elif evidence_type == "pattern" and "uniqueness" in template_name.lower():
            steps = [
                ReasoningStep(
                    step_id=1,
                    step_type="observation",
                    description="Identify the uniqueness check function calls",
                    description_cn="识别唯一性检查的函数调用",
                    source_reference="check_username_is_taken, check_email_is_taken",
                ),
                ReasoningStep(
                    step_id=2,
                    step_type="analysis",
                    description="Analyze the order of validation and data persistence",
                    description_cn="分析验证和数据持久化的顺序",
                ),
                ReasoningStep(
                    step_id=3,
                    step_type="inference",
                    description="Determine how pre-check prevents duplicate entries",
                    description_cn="判断预检查如何防止重复条目",
                    dbr_reference=f"{self.RULE_ID}-01",
                ),
                ReasoningStep(
                    step_id=4,
                    step_type="conclusion",
                    description="Conclude the data integrity guarantee mechanism",
                    description_cn="总结数据完整性保障机制",
                ),
            ]
        elif evidence_type == "call" and "token" in template_name.lower():
            steps = [
                ReasoningStep(
                    step_id=1,
                    step_type="observation",
                    description="Identify the JWT token generation call",
                    description_cn="识别JWT令牌生成调用",
                    source_reference="jwt.create_access_token_for_user",
                ),
                ReasoningStep(
                    step_id=2,
                    step_type="analysis",
                    description="Analyze when token refresh occurs in the flow",
                    description_cn="分析令牌刷新在流程中何时发生",
                ),
                ReasoningStep(
                    step_id=3,
                    step_type="inference",
                    description="Determine how token refresh maintains session consistency",
                    description_cn="判断令牌刷新如何维持会话一致性",
                    dbr_reference=f"{self.RULE_ID}-04",
                ),
                ReasoningStep(
                    step_id=4,
                    step_type="conclusion",
                    description="Conclude the session state management strategy",
                    description_cn="总结会话状态管理策略",
                ),
            ]
        else:
            # Generic reasoning steps
            steps = [
                ReasoningStep(
                    step_id=1,
                    step_type="observation",
                    description="Identify the relevant code pattern",
                    description_cn="识别相关的代码模式",
                ),
                ReasoningStep(
                    step_id=2,
                    step_type="analysis",
                    description="Analyze the implementation details",
                    description_cn="分析实现细节",
                ),
                ReasoningStep(
                    step_id=3,
                    step_type="inference",
                    description="Determine the design intent and security implications",
                    description_cn="判断设计意图和安全影响",
                ),
                ReasoningStep(
                    step_id=4,
                    step_type="conclusion",
                    description="Conclude the business rule compliance",
                    description_cn="总结业务规则的合规性",
                ),
            ]
        
        return ReasoningTemplate(
            template_id=template_id,
            template_name=template_name,
            steps=steps,
            applicable_to=applicable_to,
        )
    
    def _index_modules(self) -> None:
        """Index modules, functions, and classes for quick lookup."""
        for module in self.analysis_data.get("modules", []):
            file_path = module.get("file_path", "")
            module_name = module.get("module_name", "")
            
            self.modules_by_path[file_path] = module
            self.modules_by_name[module_name] = module
            
            # Index functions
            for func in module.get("functions", []):
                qualified_name = func.get("qualified_name", "")
                self.functions_by_name[qualified_name] = {
                    **func,
                    "_module": module_name,
                    "_file_path": file_path,
                }
            
            # Index classes and methods
            for cls in module.get("classes", []):
                class_qualified_name = cls.get("qualified_name", "")
                self.classes_by_name[class_qualified_name] = {
                    **cls,
                    "_module": module_name,
                    "_file_path": file_path,
                }
                
                # Index methods
                for method in cls.get("methods", []):
                    method_qualified_name = method.get("qualified_name", "")
                    self.functions_by_name[method_qualified_name] = {
                        **method,
                        "_module": module_name,
                        "_file_path": file_path,
                        "_class": class_qualified_name,
                    }
    
    def _find_function(self, qualified_name: str) -> Optional[Dict]:
        """Find a function by its qualified name."""
        return self.functions_by_name.get(qualified_name)
    
    def _find_module(self, module_name: str) -> Optional[Dict]:
        """Find a module by its name."""
        return self.modules_by_name.get(module_name)
    
    def _create_code_location(self, func_data: Dict) -> CodeLocation:
        """Create a CodeLocation from function data."""
        return CodeLocation(
            file_path=func_data.get("_file_path", ""),
            module_name=func_data.get("_module", ""),
            line_start=func_data.get("line_start", 0),
            line_end=func_data.get("line_end", 0),
            qualified_name=func_data.get("qualified_name", ""),
        )
    
    def _extract_login_exception_handling(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for unified login exception handling.
        
        Code Pattern:
        - Function: login
        - Variable: wrong_login_error
        - Try-except catching EntityDoesNotExist as existence_error
        - Unified error response with INCORRECT_LOGIN_INPUT
        """
        func_data = self._find_function(self.TARGET_FUNCTIONS["login"])
        if not func_data:
            logger.warning("Login function not found")
            return None
        
        local_vars = func_data.get("local_variables", [])
        calls = func_data.get("calls", [])
        file_path = func_data.get("_file_path", "")
        line_start = func_data.get("line_start", 0)
        line_end = func_data.get("line_end", 0)
        
        # Verify key patterns
        has_wrong_login_error = "wrong_login_error" in local_vars
        has_check_password_call = "user.check_password" in calls
        has_get_user_by_email = "users_repo.get_user_by_email" in calls
        
        if not (has_wrong_login_error and has_check_password_call):
            logger.warning("Login function missing expected patterns")
            return None
        
        # Extract code snippet
        code_snippet = self._extract_code_snippet(file_path, line_start, line_end)
        
        # Create DBR logic
        dbr_logic = self._create_dbr_logic(
            subcategory_id="DBR-01-03",
            trigger_type=TriggerType.EXPLICIT,
            weight=0.95,
            trigger_conditions=[
                "try-except block present",
                "wrong_login_error variable defined",
                "EntityDoesNotExist exception caught",
            ],
            matched_patterns=[
                "wrong_login_error",
                "existence_error",
                "user.check_password",
            ],
        )
        
        # Create reasoning template
        reasoning_template = self._create_reasoning_template(
            template_id="RT-LOGIN-EXCEPTION",
            template_name="Login Exception Handling Reasoning",
            evidence_type="exception_handling",
            key_elements=["wrong_login_error", "existence_error", "INCORRECT_LOGIN_INPUT"],
            applicable_to=["DBR-01-LOGIN-EXCEPTION"],
        )
        
        return CodeEvidence(
            evidence_id="DBR-01-LOGIN-EXCEPTION",
            evidence_type=EvidenceType.EXCEPTION_HANDLING,
            name="Unified Login Exception Handling",
            description="System predefines wrong_login_error variable. Uses try-except to catch "
                       "EntityDoesNotExist (named as existence_error). Returns vague error message "
                       "INCORRECT_LOGIN_INPUT to prevent user enumeration.",
            description_cn="系统预定义了 wrong_login_error 变量。通过 try-except 结构捕获 "
                          "EntityDoesNotExist（命名为 existence_error），若捕获到该异常或 "
                          "user.check_password 返回为假，则统一抛出 wrong_login_error。",
            location=self._create_code_location(func_data),
            code_snippet=code_snippet,
            dbr_logic=dbr_logic,
            reasoning_template=reasoning_template,
            related_elements=[
                "wrong_login_error",
                "existence_error",
                "EntityDoesNotExist",
                "INCORRECT_LOGIN_INPUT",
                "user.check_password",
            ],
            metadata={
                "complexity": func_data.get("complexity", 0),
                "local_variables": local_vars,
                "calls": calls,
                "has_wrong_login_error": has_wrong_login_error,
                "has_check_password_call": has_check_password_call,
                "has_get_user_by_email": has_get_user_by_email,
            }
        )
    
    def _extract_register_precheck(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for registration pre-check logic.
        
        Code Pattern:
        - Function: register
        - Parameter: user_create
        - Calls check_username_is_taken and check_email_is_taken before create_user
        - Raises HTTP_400_BAD_REQUEST if identifier is taken
        """
        func_data = self._find_function(self.TARGET_FUNCTIONS["register"])
        if not func_data:
            logger.warning("Register function not found")
            return None
        
        calls = func_data.get("calls", [])
        parameters = func_data.get("parameters", [])
        file_path = func_data.get("_file_path", "")
        line_start = func_data.get("line_start", 0)
        line_end = func_data.get("line_end", 0)
        
        # Verify key patterns
        has_user_create_param = any(p.get("name") == "user_create" for p in parameters)
        has_check_username = "check_username_is_taken" in calls
        has_check_email = "check_email_is_taken" in calls
        has_create_user = "users_repo.create_user" in calls
        has_http_exception = "HTTPException" in calls
        
        if not (has_user_create_param and has_check_username and has_check_email):
            logger.warning("Register function missing expected patterns")
            return None
        
        # Extract code snippet
        code_snippet = self._extract_code_snippet(file_path, line_start, line_end)
        
        # Create DBR logic
        dbr_logic = self._create_dbr_logic(
            subcategory_id="DBR-01-01",
            trigger_type=TriggerType.EXPLICIT,
            weight=0.9,
            trigger_conditions=[
                "user_create parameter present",
                "check_username_is_taken called before create_user",
                "check_email_is_taken called before create_user",
            ],
            matched_patterns=[
                "user_create",
                "check_username_is_taken",
                "check_email_is_taken",
                "users_repo.create_user",
            ],
        )
        
        # Create reasoning template
        reasoning_template = self._create_reasoning_template(
            template_id="RT-REGISTER-PRECHECK",
            template_name="Registration Uniqueness Check Reasoning",
            evidence_type="pattern",
            key_elements=["user_create", "check_username_is_taken", "check_email_is_taken"],
            applicable_to=["DBR-01-REGISTER-PRECHECK"],
        )
        
        return CodeEvidence(
            evidence_id="DBR-01-REGISTER-PRECHECK",
            evidence_type=EvidenceType.PATTERN,
            name="Registration Pre-check Logic",
            description="System receives user_create as input parameter. Before calling "
                       "users_repo.create_user, it awaits check_username_is_taken and "
                       "check_email_is_taken. If any identifier is taken, raises HTTP_400_BAD_REQUEST.",
            description_cn="系统接收 user_create 作为输入参数。在调用 users_repo.create_user 之前，"
                          "通过 await 执行 check_username_is_taken 和 check_email_is_taken。"
                          "若其中任一服务判定标识符已被占用，则抛出对应的 HTTP_400_BAD_REQUEST。",
            location=self._create_code_location(func_data),
            code_snippet=code_snippet,
            dbr_logic=dbr_logic,
            reasoning_template=reasoning_template,
            related_elements=[
                "user_create",
                "check_username_is_taken",
                "check_email_is_taken",
                "users_repo.create_user",
                "HTTP_400_BAD_REQUEST",
                "USERNAME_TAKEN",
                "EMAIL_TAKEN",
            ],
            metadata={
                "complexity": func_data.get("complexity", 0),
                "parameters": [p.get("name") for p in parameters],
                "calls": calls,
                "has_user_create_param": has_user_create_param,
                "has_check_username": has_check_username,
                "has_check_email": has_check_email,
                "has_create_user": has_create_user,
            }
        )
    
    def _extract_conditional_update_check(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for conditional update validation.
        
        Code Pattern:
        - Function: update_current_user
        - Compares user_update attributes with current_user attributes
        - Only triggers check when values differ
        """
        func_data = self._find_function(self.TARGET_FUNCTIONS["update_current_user"])
        if not func_data:
            logger.warning("Update current user function not found")
            return None
        
        calls = func_data.get("calls", [])
        parameters = func_data.get("parameters", [])
        file_path = func_data.get("_file_path", "")
        line_start = func_data.get("line_start", 0)
        line_end = func_data.get("line_end", 0)
        
        # Verify key patterns
        has_user_update_param = any(p.get("name") == "user_update" for p in parameters)
        has_current_user_param = any(p.get("name") == "current_user" for p in parameters)
        has_check_username = "check_username_is_taken" in calls
        has_check_email = "check_email_is_taken" in calls
        has_update_user = "users_repo.update_user" in calls
        
        # High complexity indicates conditional logic
        complexity = func_data.get("complexity", 0)
        has_conditional_logic = complexity >= 5  # Multiple if conditions
        
        if not (has_user_update_param and has_current_user_param):
            logger.warning("Update function missing expected parameters")
            return None
        
        # Extract code snippet
        code_snippet = self._extract_code_snippet(file_path, line_start, line_end)
        
        # Create DBR logic
        dbr_logic = self._create_dbr_logic(
            subcategory_id="DBR-01-01",
            trigger_type=TriggerType.COMPOSITE,
            weight=0.85,
            trigger_conditions=[
                "user_update parameter present",
                "current_user parameter present",
                "conditional comparison before check",
                "complexity >= 5 indicating multiple conditions",
            ],
            matched_patterns=[
                "user_update.username != current_user.username",
                "user_update.email != current_user.email",
                "check_username_is_taken",
                "check_email_is_taken",
            ],
        )
        
        # Create reasoning template
        reasoning_template = self._create_reasoning_template(
            template_id="RT-UPDATE-CONDITIONAL",
            template_name="Conditional Update Uniqueness Check Reasoning",
            evidence_type="pattern",
            key_elements=["user_update", "current_user", "conditional_check"],
            applicable_to=["DBR-01-UPDATE-CONDITIONAL"],
        )
        
        return CodeEvidence(
            evidence_id="DBR-01-UPDATE-CONDITIONAL",
            evidence_type=EvidenceType.PATTERN,
            name="Conditional Update Validation",
            description="System compares user_update attributes with current_user's original "
                       "attributes. Only triggers check_username_is_taken or check_email_is_taken "
                       "when the values differ from existing ones.",
            description_cn="系统对比 user_update 传入的属性与 current_user 的原始属性。"
                          "仅当 user_update.username 或 user_update.email 与现有值不一致时，"
                          "才会触发 check_username_is_taken 或 check_email_is_taken 的查重逻辑。",
            location=self._create_code_location(func_data),
            code_snippet=code_snippet,
            dbr_logic=dbr_logic,
            reasoning_template=reasoning_template,
            related_elements=[
                "user_update",
                "current_user",
                "user_update.username",
                "user_update.email",
                "current_user.username",
                "current_user.email",
                "check_username_is_taken",
                "check_email_is_taken",
            ],
            metadata={
                "complexity": complexity,
                "parameters": [p.get("name") for p in parameters],
                "calls": calls,
                "has_user_update_param": has_user_update_param,
                "has_current_user_param": has_current_user_param,
                "has_conditional_logic": has_conditional_logic,
            }
        )
    
    def _extract_token_refresh_mechanism(self) -> List[CodeEvidence]:
        """
        Extract evidence for token refresh mechanism.
        
        Code Pattern:
        - Multiple functions call jwt.create_access_token_for_user
        - Returns token variable wrapped in UserWithToken
        - Covers login, register, retrieve_current_user, update_current_user
        """
        evidences = []
        
        for func_name, qualified_name in self.TARGET_FUNCTIONS.items():
            func_data = self._find_function(qualified_name)
            if not func_data:
                continue
            
            calls = func_data.get("calls", [])
            local_vars = func_data.get("local_variables", [])
            file_path = func_data.get("_file_path", "")
            line_start = func_data.get("line_start", 0)
            line_end = func_data.get("line_end", 0)
            
            # Check for token generation pattern
            has_create_token = "jwt.create_access_token_for_user" in calls
            has_token_var = "token" in local_vars
            has_user_with_token = "UserWithToken" in calls
            
            if has_create_token and has_token_var:
                # Extract code snippet
                code_snippet = self._extract_code_snippet(file_path, line_start, line_end)
                
                # Create DBR logic
                dbr_logic = self._create_dbr_logic(
                    subcategory_id="DBR-01-04",
                    trigger_type=TriggerType.EXPLICIT,
                    weight=0.8,
                    trigger_conditions=[
                        "jwt.create_access_token_for_user called",
                        "token variable assigned",
                        "UserWithToken used in response",
                    ],
                    matched_patterns=[
                        "jwt.create_access_token_for_user",
                        "token",
                        "UserWithToken",
                    ],
                )
                
                # Create reasoning template
                reasoning_template = self._create_reasoning_template(
                    template_id=f"RT-TOKEN-{func_name.upper()}",
                    template_name=f"Token Refresh in {func_name} Reasoning",
                    evidence_type="call",
                    key_elements=["jwt.create_access_token_for_user", "token", "UserWithToken"],
                    applicable_to=[f"DBR-01-TOKEN-{func_name.upper()}"],
                )
                
                evidence = CodeEvidence(
                    evidence_id=f"DBR-01-TOKEN-{func_name.upper()}",
                    evidence_type=EvidenceType.CALL,
                    name=f"Token Refresh in {func_name}",
                    description=f"The {func_name} function calls jwt.create_access_token_for_user "
                               f"to generate token variable, wrapped in UserWithToken domain model.",
                    description_cn=f"函数 {func_name} 通过调用 jwt.create_access_token_for_user "
                                  f"生成 token 变量，并封装在 UserWithToken 领域模型中返回。",
                    location=self._create_code_location(func_data),
                    code_snippet=code_snippet,
                    dbr_logic=dbr_logic,
                    reasoning_template=reasoning_template,
                    related_elements=[
                        "jwt.create_access_token_for_user",
                        "token",
                        "UserWithToken",
                        "UserInResponse",
                    ],
                    metadata={
                        "function_name": func_name,
                        "has_create_token": has_create_token,
                        "has_token_var": has_token_var,
                        "has_user_with_token": has_user_with_token,
                        "calls": calls,
                    }
                )
                evidences.append(evidence)
        
        return evidences
    
    def _extract_repository_atomicity(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for repository storage atomicity.
        
        Code Pattern:
        - UsersRepository.create_user uses transaction
        - Password is hashed before persistence
        """
        # Find the UsersRepository class
        users_repo_module = self._find_module("app.db.repositories.users")
        if not users_repo_module:
            logger.warning("UsersRepository module not found")
            return None
        
        # Find create_user method
        create_user_data = self._find_function(self.REPOSITORY_METHODS["create_user"])
        if not create_user_data:
            logger.warning("create_user method not found")
            return None
        
        calls = create_user_data.get("calls", [])
        file_path = create_user_data.get("_file_path", "")
        line_start = create_user_data.get("line_start", 0)
        line_end = create_user_data.get("line_end", 0)
        
        # Check for transaction and password hashing
        has_transaction = "self.connection.transaction" in calls
        has_password_change = "user.change_password" in calls
        has_create_query = "queries.create_new_user" in calls
        
        # Extract code snippet
        code_snippet = self._extract_code_snippet(file_path, line_start, line_end)
        
        # Create DBR logic
        dbr_logic = self._create_dbr_logic(
            subcategory_id="DBR-01-02",
            trigger_type=TriggerType.EXPLICIT,
            weight=0.9,
            trigger_conditions=[
                "transaction context manager used",
                "change_password called for hashing",
                "atomic database operation",
            ],
            matched_patterns=[
                "self.connection.transaction",
                "user.change_password",
                "hashed_password",
                "salt",
            ],
        )
        
        # Create reasoning template
        reasoning_template = self._create_reasoning_template(
            template_id="RT-REPO-ATOMICITY",
            template_name="Repository Atomicity Reasoning",
            evidence_type="pattern",
            key_elements=["transaction", "change_password", "hashed_password"],
            applicable_to=["DBR-01-REPO-ATOMICITY"],
        )
        
        return CodeEvidence(
            evidence_id="DBR-01-REPO-ATOMICITY",
            evidence_type=EvidenceType.PATTERN,
            name="Repository Storage Atomicity",
            description="Account creation through UsersRepository ensures atomicity using "
                       "database transaction. Password is hashed via change_password before persistence.",
            description_cn="账户创建过程通过 UsersRepository 确保原子性，密码经哈希处理后持久化。"
                          "使用数据库事务保证操作的原子性。",
            location=self._create_code_location(create_user_data),
            code_snippet=code_snippet,
            dbr_logic=dbr_logic,
            reasoning_template=reasoning_template,
            related_elements=[
                "UsersRepository",
                "create_user",
                "change_password",
                "self.connection.transaction",
                "hashed_password",
                "salt",
            ],
            metadata={
                "has_transaction": has_transaction,
                "has_password_change": has_password_change,
                "has_create_query": has_create_query,
                "calls": calls,
            }
        )
    
    def _extract_uniqueness_service(self) -> List[CodeEvidence]:
        """
        Extract evidence for uniqueness check services.
        
        Code Pattern:
        - check_username_is_taken function
        - check_email_is_taken function
        - Both catch EntityDoesNotExist exception
        """
        evidences = []
        
        for service_name in ["check_username_is_taken", "check_email_is_taken"]:
            qualified_name = self.SERVICE_FUNCTIONS[service_name]
            func_data = self._find_function(qualified_name)
            if not func_data:
                continue
            
            calls = func_data.get("calls", [])
            file_path = func_data.get("_file_path", "")
            line_start = func_data.get("line_start", 0)
            line_end = func_data.get("line_end", 0)
            
            # Extract code snippet
            code_snippet = self._extract_code_snippet(file_path, line_start, line_end)
            
            # Create DBR logic
            dbr_logic = self._create_dbr_logic(
                subcategory_id="DBR-01-01",
                trigger_type=TriggerType.EXPLICIT,
                weight=0.85,
                trigger_conditions=[
                    f"{service_name} function defined",
                    "EntityDoesNotExist exception handling",
                    "Repository query for existence check",
                ],
                matched_patterns=[
                    service_name,
                    "EntityDoesNotExist",
                    "repo.get_user_by_" + ("username" if "username" in service_name else "email"),
                ],
            )
            
            # Create reasoning template
            reasoning_template = self._create_reasoning_template(
                template_id=f"RT-SERVICE-{service_name.upper().replace('_', '-')}",
                template_name=f"Uniqueness Service {service_name} Reasoning",
                evidence_type="function",
                key_elements=[service_name, "EntityDoesNotExist", "UsersRepository"],
                applicable_to=[f"DBR-01-SERVICE-{service_name.upper().replace('_', '-')}"],
            )
            
            evidence = CodeEvidence(
                evidence_id=f"DBR-01-SERVICE-{service_name.upper().replace('_', '-')}",
                evidence_type=EvidenceType.FUNCTION,
                name=f"Uniqueness Service: {service_name}",
                description=f"The {service_name} function queries the repository and catches "
                           f"EntityDoesNotExist to determine availability.",
                description_cn=f"函数 {service_name} 查询仓库并捕获 EntityDoesNotExist 异常来判断唯一性。",
                location=self._create_code_location(func_data),
                code_snippet=code_snippet,
                dbr_logic=dbr_logic,
                reasoning_template=reasoning_template,
                related_elements=[
                    service_name,
                    "EntityDoesNotExist",
                    "UsersRepository",
                ],
                metadata={
                    "calls": calls,
                    "return_type": func_data.get("return_type"),
                }
            )
            evidences.append(evidence)
        
        return evidences
    
    def generate_rule_metadata(self) -> Optional[RuleMetadata]:
        """Generate complete rule metadata for DBR-01."""
        if not self.analysis_data:
            if not self.load_analysis():
                return None
        
        # Extract all evidences
        login_exception = self._extract_login_exception_handling()
        register_precheck = self._extract_register_precheck()
        conditional_update = self._extract_conditional_update_check()
        token_evidences = self._extract_token_refresh_mechanism()
        repo_atomicity = self._extract_repository_atomicity()
        uniqueness_services = self._extract_uniqueness_service()
        
        # Create subcategories
        subcategories = []
        
        # Collect all reasoning templates for rule-level aggregation
        all_reasoning_templates = []
        
        # Subcategory 1: Uniqueness Interception
        uniqueness_evidences = []
        if register_precheck:
            uniqueness_evidences.append(register_precheck)
            if register_precheck.reasoning_template:
                all_reasoning_templates.append(register_precheck.reasoning_template)
        if conditional_update:
            uniqueness_evidences.append(conditional_update)
            if conditional_update.reasoning_template:
                all_reasoning_templates.append(conditional_update.reasoning_template)
        for evidence in uniqueness_services:
            if evidence.reasoning_template:
                all_reasoning_templates.append(evidence.reasoning_template)
        uniqueness_evidences.extend(uniqueness_services)
        
        if uniqueness_evidences:
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-01",
                name="Multi-scenario Uniqueness Interception",
                name_cn="多场景唯一性拦截",
                description="System enforces uniqueness checks during user registration and profile "
                           "updates. If identifier is already taken, system explicitly intercepts "
                           "with 400 Bad Request.",
                description_cn="系统在用户注册及资料更新时，强制执行唯一性检查。"
                              "若标识符已被占用，系统通过 400 Bad Request 显式拦截。",
                evidences=uniqueness_evidences,
                question_templates=self.QUESTION_TEMPLATES.get("DBR-01-01", []),
                question_templates_cn=self.QUESTION_TEMPLATES.get("DBR-01-01-CN", []),
            ))
        
        # Subcategory 2: Account Security & Atomicity
        security_evidences = []
        if repo_atomicity:
            security_evidences.append(repo_atomicity)
            if repo_atomicity.reasoning_template:
                all_reasoning_templates.append(repo_atomicity.reasoning_template)
        
        if security_evidences:
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-02",
                name="Account Security & Storage Atomicity",
                name_cn="账户安全性与存储原子性",
                description="Account creation process ensures atomicity through UsersRepository. "
                           "Password is hashed before persistence.",
                description_cn="账户创建过程通过 UsersRepository 确保原子性，密码经哈希处理后持久化。",
                evidences=security_evidences,
                question_templates=self.QUESTION_TEMPLATES.get("DBR-01-02", []),
                question_templates_cn=self.QUESTION_TEMPLATES.get("DBR-01-02-CN", []),
            ))
        
        # Subcategory 3: Authentication Security Feedback
        auth_feedback_evidences = []
        if login_exception:
            auth_feedback_evidences.append(login_exception)
            if login_exception.reasoning_template:
                all_reasoning_templates.append(login_exception.reasoning_template)
        
        if auth_feedback_evidences:
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-03",
                name="Authentication Security Feedback",
                name_cn="身份验证安全反馈",
                description="Login uniformly catches exceptions and returns vague error message "
                           "INCORRECT_LOGIN_INPUT to prevent user enumeration attacks.",
                description_cn="登录时统一捕获异常，返回模糊错误信息 INCORRECT_LOGIN_INPUT，防止用户枚举。",
                evidences=auth_feedback_evidences,
                question_templates=self.QUESTION_TEMPLATES.get("DBR-01-03", []),
                question_templates_cn=self.QUESTION_TEMPLATES.get("DBR-01-03-CN", []),
            ))
        
        # Subcategory 4: Token Refresh Mechanism
        if token_evidences:
            for evidence in token_evidences:
                if evidence.reasoning_template:
                    all_reasoning_templates.append(evidence.reasoning_template)
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-04",
                name="Dynamic Session State Maintenance",
                name_cn="动态会话状态维护",
                description="After successful operation, system regenerates and returns JWT token "
                           "to maintain client session state consistency.",
                description_cn="操作成功后重新生成并返回 JWT 令牌，维持客户端会话状态一致性。",
                evidences=token_evidences,
                question_templates=self.QUESTION_TEMPLATES.get("DBR-01-04", []),
                question_templates_cn=self.QUESTION_TEMPLATES.get("DBR-01-04-CN", []),
            ))
        
        # Collect all related files and functions
        related_files = set()
        related_functions = set()
        
        for subcat in subcategories:
            for evidence in subcat.evidences:
                related_files.add(evidence.location.file_path)
                if evidence.location.qualified_name:
                    related_functions.add(evidence.location.qualified_name)
        
        # Create parser info
        parser_info = ParserInfo(
            name=PARSER_NAME,
            version=PARSER_VERSION,
            analysis_timestamp=self.analysis_data.get("analysis_timestamp", ""),
            source_file=str(self.analysis_json_path),
            capabilities=[
                "AST parsing",
                "Function extraction",
                "Class extraction",
                "Call graph analysis",
                "FastAPI route detection",
                "Complexity calculation",
            ],
        )
        
        # Create data cleaning info
        data_cleaning = DataCleaningInfo(
            cleaned=True,
            desensitized=False,
            cleaning_rules=[
                "Remove internal comments",
                "Normalize whitespace",
                "Extract relevant code blocks only",
            ],
            excluded_patterns=[
                "__pycache__",
                "*.pyc",
                "test_*.py",  # Test files excluded from evidence
            ],
        )
        
        # Create Q&A generation config
        qa_config = QAGenerationConfig(
            default_language="en",
            supported_languages=["en", "zh"],
            default_temperature=0.7,
            include_code_snippets=True,
            include_reasoning_trace=True,
            max_snippet_lines=50,
        )
        
        # Create the rule metadata
        rule_metadata = RuleMetadata(
            rule_id=self.RULE_ID,
            rule_name=self.RULE_NAME,
            rule_name_cn=self.RULE_NAME_CN,
            description="This rule ensures authentication and credential integrity through: "
                       "(1) Multi-scenario uniqueness interception during sign-up and update, "
                       "(2) Account security and storage atomicity with password hashing, "
                       "(3) Authentication security feedback with vague error messages, "
                       "(4) Dynamic session state maintenance via JWT token refresh.",
            description_cn="本规则通过以下机制确保身份准入与账户凭据完整性："
                          "（1）注册及更新时的多场景唯一性拦截；"
                          "（2）账户安全性与存储原子性（密码哈希）；"
                          "（3）身份验证安全反馈（模糊错误信息）；"
                          "（4）动态会话状态维护（JWT令牌刷新）。",
            version=RULE_MAPPING_VERSION,
            created_at=datetime.now().isoformat(),
            analysis_source=str(self.analysis_json_path),
            project_name=self.analysis_data.get("project_name", "unknown"),
            subcategories=subcategories,
            related_files=sorted(related_files),
            related_functions=sorted(related_functions),
            dependencies=[
                "fastapi",
                "starlette",
                "jwt",
                "pydantic",
            ],
            tags=[
                "authentication",
                "security",
                "credential",
                "jwt",
                "user-management",
                "uniqueness-check",
                "password-hashing",
            ],
            # New fields for Q&A schema compatibility
            parser_info=parser_info,
            data_cleaning=data_cleaning,
            qa_config=qa_config,
            reasoning_templates=all_reasoning_templates,
            source_code_root=str(self.source_root) if self.source_root else "",
        )
        
        return rule_metadata


def convert_to_dict(obj: Any) -> Any:
    """Convert dataclass instances to dictionaries recursively."""
    if hasattr(obj, '__dataclass_fields__'):
        result = {}
        for k, v in asdict(obj).items():
            result[k] = convert_to_dict(v)
        return result
    elif isinstance(obj, list):
        return [convert_to_dict(item) for item in obj]
    elif isinstance(obj, dict):
        return {k: convert_to_dict(v) for k, v in obj.items()}
    elif isinstance(obj, Enum):
        return obj.value
    else:
        return obj


def generate_dbr01_metadata(
    analysis_json_path: str,
    output_path: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    """
    Generate DBR-01 rule metadata from AST analysis JSON.
    
    Args:
        analysis_json_path: Path to the AST analysis JSON file
        output_path: Optional path to save the rule metadata JSON
        
    Returns:
        Dictionary containing the rule metadata, or None if failed
    """
    mapper = DBR01RuleMapper(analysis_json_path)
    
    if not mapper.load_analysis():
        return None
    
    rule_metadata = mapper.generate_rule_metadata()
    if not rule_metadata:
        logger.error("Failed to generate rule metadata")
        return None
    
    # Convert to dictionary
    result = convert_to_dict(rule_metadata)
    
    # Save to file if output path provided
    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        logger.info(f"Rule metadata saved to: {output_path}")
    
    return result


def print_rule_summary(metadata: Dict[str, Any]) -> None:
    """Print a human-readable summary of the rule metadata."""
    print("\n" + "=" * 70)
    print(f"Rule Metadata Summary (Q&A Schema Compatible)")
    print("=" * 70)
    
    print(f"\nRule ID: {metadata.get('rule_id')}")
    print(f"Rule Name: {metadata.get('rule_name')}")
    print(f"Rule Name (CN): {metadata.get('rule_name_cn')}")
    print(f"Version: {metadata.get('version')}")
    print(f"Created At: {metadata.get('created_at')}")
    print(f"Project: {metadata.get('project_name')}")
    
    print(f"\nDescription:")
    print(f"  {metadata.get('description')}")
    
    print(f"\n描述:")
    print(f"  {metadata.get('description_cn')}")
    
    # Parser info
    parser_info = metadata.get('parser_info', {})
    if parser_info:
        print(f"\n--- Parser Info ---")
        print(f"  Parser: {parser_info.get('name')} v{parser_info.get('version')}")
        print(f"  Capabilities: {', '.join(parser_info.get('capabilities', []))}")
    
    # Q&A Config
    qa_config = metadata.get('qa_config', {})
    if qa_config:
        print(f"\n--- Q&A Generation Config ---")
        print(f"  Languages: {', '.join(qa_config.get('supported_languages', []))}")
        print(f"  Temperature: {qa_config.get('default_temperature')}")
        print(f"  Include Code Snippets: {qa_config.get('include_code_snippets')}")
        print(f"  Include Reasoning Trace: {qa_config.get('include_reasoning_trace')}")
    
    print(f"\n--- Subcategories ({len(metadata.get('subcategories', []))}) ---")
    for i, subcat in enumerate(metadata.get('subcategories', []), 1):
        print(f"\n  {i}. {subcat.get('name')} ({subcat.get('subcategory_id')})")
        print(f"     {subcat.get('name_cn')}")
        print(f"     Evidences: {len(subcat.get('evidences', []))}")
        print(f"     Question Templates: {len(subcat.get('question_templates', []))}")
        
        for evidence in subcat.get('evidences', []):
            print(f"       - [{evidence.get('evidence_type')}] {evidence.get('name')}")
            loc = evidence.get('location', {})
            print(f"         File: {loc.get('file_path')}:{loc.get('line_start')}-{loc.get('line_end')}")
            
            # Show code snippet info if available
            code_snippet = evidence.get('code_snippet')
            if code_snippet and code_snippet.get('source_hash'):
                print(f"         Code Hash: {code_snippet.get('source_hash')[:8]}...")
            
            # Show DBR logic info if available
            dbr_logic = evidence.get('dbr_logic')
            if dbr_logic:
                print(f"         DBR Logic: weight={dbr_logic.get('weight')}, "
                      f"trigger={dbr_logic.get('trigger_type')}")
            
            # Show reasoning template info if available
            reasoning = evidence.get('reasoning_template')
            if reasoning:
                print(f"         Reasoning Template: {reasoning.get('template_id')} "
                      f"({len(reasoning.get('steps', []))} steps)")
    
    print(f"\n--- Related Files ({len(metadata.get('related_files', []))}) ---")
    for file_path in metadata.get('related_files', []):
        print(f"  - {file_path}")
    
    print(f"\n--- Reasoning Templates ({len(metadata.get('reasoning_templates', []))}) ---")
    for template in metadata.get('reasoning_templates', []):
        print(f"  - {template.get('template_id')}: {template.get('template_name')}")
    
    print(f"\n--- Tags ({len(metadata.get('tags', []))}) ---")
    print(f"  {', '.join(metadata.get('tags', []))}")
    
    # Data cleaning info
    data_cleaning = metadata.get('data_cleaning', {})
    if data_cleaning:
        print(f"\n--- Data Cleaning ---")
        print(f"  Cleaned: {data_cleaning.get('cleaned')}")
        print(f"  Desensitized: {data_cleaning.get('desensitized')}")
    
    print("\n" + "=" * 70)


def main():
    """Main entry point for the rule mapping generator."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='DBR-01 Rule Mapping Generator',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Generate rule metadata from analysis JSON
  python rule_mapping.py /path/to/analysis.json
  
  # Generate and save to specific output file
  python rule_mapping.py /path/to/analysis.json -o rule_metadata.json
  
  # Generate with summary output
  python rule_mapping.py /path/to/analysis.json --summary
        """
    )
    
    parser.add_argument(
        'analysis_path',
        nargs='?',
        default=None,
        help='Path to the AST analysis JSON file'
    )
    
    parser.add_argument(
        '-o', '--output',
        default=None,
        help='Output file path for rule metadata JSON'
    )
    
    parser.add_argument(
        '-s', '--summary',
        action='store_true',
        help='Print human-readable summary to console'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose logging'
    )
    
    args = parser.parse_args()
    
    # Configure logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Default paths
    script_dir = Path(__file__).parent.resolve()
    workspace_root = script_dir.parent.parent
    
    if args.analysis_path is None:
        args.analysis_path = workspace_root / 'data' / 'fastapi_analysis_result.json'
    
    if args.output is None:
        args.output = workspace_root / 'data' / 'dbr01_rule_metadata.json'
    
    # Verify analysis file exists
    analysis_path = Path(args.analysis_path)
    if not analysis_path.exists():
        print(f"Error: Analysis file not found: {analysis_path}")
        print("Please run fast_api_analyzer.py first to generate the analysis JSON.")
        return None
    
    # Generate rule metadata
    print(f"Reading analysis from: {analysis_path}")
    result = generate_dbr01_metadata(
        str(analysis_path),
        output_path=str(args.output) if args.output else None
    )
    
    if result:
        # Print summary if requested or by default when output is specified
        if args.summary or args.output:
            print_rule_summary(result)
        
        if args.output:
            print(f"\nRule metadata saved to: {args.output}")
        
        return result
    else:
        print("Failed to generate rule metadata")
        return None


if __name__ == '__main__':
    main()
