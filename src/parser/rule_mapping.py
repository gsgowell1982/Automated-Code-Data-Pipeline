#!/usr/bin/env python3
"""
Rule Mapping Generator - DBR-01: Authentication & Credential Integrity

This module reads the AST analysis JSON file generated by fast_api_analyzer.py
and maps the code evidence to the DBR-01 rule metadata.

DBR-01 Rule Description:
身份准入与账户凭据完整性（Authentication & Credential Integrity）

Business Logic:
1. Multi-scenario uniqueness interception (Sign-up & Update)
2. Account security and storage atomicity 
3. Authentication security feedback (Login)
4. Dynamic session state maintenance (Token Refresh)

Author: Auto-generated
Version: 1.0.0
"""

import json
import os
import logging
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Optional, Any, Set
from enum import Enum

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EvidenceType(str, Enum):
    """Types of code evidence for rule mapping."""
    FUNCTION = "function"
    VARIABLE = "variable"
    EXCEPTION_HANDLING = "exception_handling"
    CALL = "call"
    IMPORT = "import"
    PATTERN = "pattern"


@dataclass
class CodeLocation:
    """Location information for code evidence."""
    file_path: str
    module_name: str
    line_start: int
    line_end: int
    qualified_name: Optional[str] = None


@dataclass
class CodeEvidence:
    """Evidence of a rule implementation in code."""
    evidence_id: str
    evidence_type: EvidenceType
    name: str
    description: str
    description_cn: str
    location: CodeLocation
    related_elements: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RuleSubCategory:
    """Sub-category of a rule with specific code evidence."""
    subcategory_id: str
    name: str
    name_cn: str
    description: str
    description_cn: str
    evidences: List[CodeEvidence] = field(default_factory=list)


@dataclass
class RuleMetadata:
    """Complete metadata for a design rule."""
    rule_id: str
    rule_name: str
    rule_name_cn: str
    description: str
    description_cn: str
    version: str
    created_at: str
    analysis_source: str
    project_name: str
    subcategories: List[RuleSubCategory] = field(default_factory=list)
    related_files: List[str] = field(default_factory=list)
    related_functions: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    tags: List[str] = field(default_factory=list)


class DBR01RuleMapper:
    """
    Mapper for DBR-01: Authentication & Credential Integrity rule.
    
    This class extracts code evidence from the AST analysis JSON and maps
    it to the structured DBR-01 rule metadata.
    """
    
    RULE_ID = "DBR-01"
    RULE_NAME = "Authentication & Credential Integrity"
    RULE_NAME_CN = "身份准入与账户凭据完整性"
    
    # Target functions for rule mapping
    TARGET_FUNCTIONS = {
        "login": "app.api.routes.authentication.login",
        "register": "app.api.routes.authentication.register",
        "retrieve_current_user": "app.api.routes.users.retrieve_current_user",
        "update_current_user": "app.api.routes.users.update_current_user",
    }
    
    # Service functions
    SERVICE_FUNCTIONS = {
        "check_username_is_taken": "app.services.authentication.check_username_is_taken",
        "check_email_is_taken": "app.services.authentication.check_email_is_taken",
        "create_access_token_for_user": "app.services.jwt.create_access_token_for_user",
    }
    
    # Repository methods
    REPOSITORY_METHODS = {
        "create_user": "app.db.repositories.users.UsersRepository.create_user",
        "update_user": "app.db.repositories.users.UsersRepository.update_user",
        "get_user_by_email": "app.db.repositories.users.UsersRepository.get_user_by_email",
        "get_user_by_username": "app.db.repositories.users.UsersRepository.get_user_by_username",
    }
    
    # Key variables to track
    KEY_VARIABLES = {
        "wrong_login_error",
        "user_create",
        "user_update",
        "current_user",
        "token",
        "existence_error",
    }
    
    # Key imports
    KEY_IMPORTS = {
        "EntityDoesNotExist",
        "HTTP_400_BAD_REQUEST",
        "HTTPException",
        "UsersRepository",
        "UserWithToken",
    }

    def __init__(self, analysis_json_path: str):
        """
        Initialize the rule mapper.
        
        Args:
            analysis_json_path: Path to the AST analysis JSON file
        """
        self.analysis_json_path = Path(analysis_json_path)
        self.analysis_data: Dict[str, Any] = {}
        self.modules_by_path: Dict[str, Dict] = {}
        self.modules_by_name: Dict[str, Dict] = {}
        self.functions_by_name: Dict[str, Dict] = {}
        self.classes_by_name: Dict[str, Dict] = {}
        
    def load_analysis(self) -> bool:
        """Load and parse the analysis JSON file."""
        if not self.analysis_json_path.exists():
            logger.error(f"Analysis file not found: {self.analysis_json_path}")
            return False
            
        try:
            with open(self.analysis_json_path, 'r', encoding='utf-8') as f:
                self.analysis_data = json.load(f)
            logger.info(f"Loaded analysis from: {self.analysis_json_path}")
            
            # Index modules for quick lookup
            self._index_modules()
            return True
            
        except Exception as e:
            logger.error(f"Error loading analysis JSON: {e}")
            return False
    
    def _index_modules(self) -> None:
        """Index modules, functions, and classes for quick lookup."""
        for module in self.analysis_data.get("modules", []):
            file_path = module.get("file_path", "")
            module_name = module.get("module_name", "")
            
            self.modules_by_path[file_path] = module
            self.modules_by_name[module_name] = module
            
            # Index functions
            for func in module.get("functions", []):
                qualified_name = func.get("qualified_name", "")
                self.functions_by_name[qualified_name] = {
                    **func,
                    "_module": module_name,
                    "_file_path": file_path,
                }
            
            # Index classes and methods
            for cls in module.get("classes", []):
                class_qualified_name = cls.get("qualified_name", "")
                self.classes_by_name[class_qualified_name] = {
                    **cls,
                    "_module": module_name,
                    "_file_path": file_path,
                }
                
                # Index methods
                for method in cls.get("methods", []):
                    method_qualified_name = method.get("qualified_name", "")
                    self.functions_by_name[method_qualified_name] = {
                        **method,
                        "_module": module_name,
                        "_file_path": file_path,
                        "_class": class_qualified_name,
                    }
    
    def _find_function(self, qualified_name: str) -> Optional[Dict]:
        """Find a function by its qualified name."""
        return self.functions_by_name.get(qualified_name)
    
    def _find_module(self, module_name: str) -> Optional[Dict]:
        """Find a module by its name."""
        return self.modules_by_name.get(module_name)
    
    def _create_code_location(self, func_data: Dict) -> CodeLocation:
        """Create a CodeLocation from function data."""
        return CodeLocation(
            file_path=func_data.get("_file_path", ""),
            module_name=func_data.get("_module", ""),
            line_start=func_data.get("line_start", 0),
            line_end=func_data.get("line_end", 0),
            qualified_name=func_data.get("qualified_name", ""),
        )
    
    def _extract_login_exception_handling(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for unified login exception handling.
        
        Code Pattern:
        - Function: login
        - Variable: wrong_login_error
        - Try-except catching EntityDoesNotExist as existence_error
        - Unified error response with INCORRECT_LOGIN_INPUT
        """
        func_data = self._find_function(self.TARGET_FUNCTIONS["login"])
        if not func_data:
            logger.warning("Login function not found")
            return None
        
        local_vars = func_data.get("local_variables", [])
        calls = func_data.get("calls", [])
        
        # Verify key patterns
        has_wrong_login_error = "wrong_login_error" in local_vars
        has_check_password_call = "user.check_password" in calls
        has_get_user_by_email = "users_repo.get_user_by_email" in calls
        
        if not (has_wrong_login_error and has_check_password_call):
            logger.warning("Login function missing expected patterns")
            return None
        
        return CodeEvidence(
            evidence_id="DBR-01-LOGIN-EXCEPTION",
            evidence_type=EvidenceType.EXCEPTION_HANDLING,
            name="Unified Login Exception Handling",
            description="System predefines wrong_login_error variable. Uses try-except to catch "
                       "EntityDoesNotExist (named as existence_error). Returns vague error message "
                       "INCORRECT_LOGIN_INPUT to prevent user enumeration.",
            description_cn="系统预定义了 wrong_login_error 变量。通过 try-except 结构捕获 "
                          "EntityDoesNotExist（命名为 existence_error），若捕获到该异常或 "
                          "user.check_password 返回为假，则统一抛出 wrong_login_error。",
            location=self._create_code_location(func_data),
            related_elements=[
                "wrong_login_error",
                "existence_error",
                "EntityDoesNotExist",
                "INCORRECT_LOGIN_INPUT",
                "user.check_password",
            ],
            metadata={
                "complexity": func_data.get("complexity", 0),
                "local_variables": local_vars,
                "calls": calls,
                "has_wrong_login_error": has_wrong_login_error,
                "has_check_password_call": has_check_password_call,
                "has_get_user_by_email": has_get_user_by_email,
            }
        )
    
    def _extract_register_precheck(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for registration pre-check logic.
        
        Code Pattern:
        - Function: register
        - Parameter: user_create
        - Calls check_username_is_taken and check_email_is_taken before create_user
        - Raises HTTP_400_BAD_REQUEST if identifier is taken
        """
        func_data = self._find_function(self.TARGET_FUNCTIONS["register"])
        if not func_data:
            logger.warning("Register function not found")
            return None
        
        calls = func_data.get("calls", [])
        parameters = func_data.get("parameters", [])
        
        # Verify key patterns
        has_user_create_param = any(p.get("name") == "user_create" for p in parameters)
        has_check_username = "check_username_is_taken" in calls
        has_check_email = "check_email_is_taken" in calls
        has_create_user = "users_repo.create_user" in calls
        has_http_exception = "HTTPException" in calls
        
        if not (has_user_create_param and has_check_username and has_check_email):
            logger.warning("Register function missing expected patterns")
            return None
        
        return CodeEvidence(
            evidence_id="DBR-01-REGISTER-PRECHECK",
            evidence_type=EvidenceType.PATTERN,
            name="Registration Pre-check Logic",
            description="System receives user_create as input parameter. Before calling "
                       "users_repo.create_user, it awaits check_username_is_taken and "
                       "check_email_is_taken. If any identifier is taken, raises HTTP_400_BAD_REQUEST.",
            description_cn="系统接收 user_create 作为输入参数。在调用 users_repo.create_user 之前，"
                          "通过 await 执行 check_username_is_taken 和 check_email_is_taken。"
                          "若其中任一服务判定标识符已被占用，则抛出对应的 HTTP_400_BAD_REQUEST。",
            location=self._create_code_location(func_data),
            related_elements=[
                "user_create",
                "check_username_is_taken",
                "check_email_is_taken",
                "users_repo.create_user",
                "HTTP_400_BAD_REQUEST",
                "USERNAME_TAKEN",
                "EMAIL_TAKEN",
            ],
            metadata={
                "complexity": func_data.get("complexity", 0),
                "parameters": [p.get("name") for p in parameters],
                "calls": calls,
                "has_user_create_param": has_user_create_param,
                "has_check_username": has_check_username,
                "has_check_email": has_check_email,
                "has_create_user": has_create_user,
            }
        )
    
    def _extract_conditional_update_check(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for conditional update validation.
        
        Code Pattern:
        - Function: update_current_user
        - Compares user_update attributes with current_user attributes
        - Only triggers check when values differ
        """
        func_data = self._find_function(self.TARGET_FUNCTIONS["update_current_user"])
        if not func_data:
            logger.warning("Update current user function not found")
            return None
        
        calls = func_data.get("calls", [])
        parameters = func_data.get("parameters", [])
        
        # Verify key patterns
        has_user_update_param = any(p.get("name") == "user_update" for p in parameters)
        has_current_user_param = any(p.get("name") == "current_user" for p in parameters)
        has_check_username = "check_username_is_taken" in calls
        has_check_email = "check_email_is_taken" in calls
        has_update_user = "users_repo.update_user" in calls
        
        # High complexity indicates conditional logic
        complexity = func_data.get("complexity", 0)
        has_conditional_logic = complexity >= 5  # Multiple if conditions
        
        if not (has_user_update_param and has_current_user_param):
            logger.warning("Update function missing expected parameters")
            return None
        
        return CodeEvidence(
            evidence_id="DBR-01-UPDATE-CONDITIONAL",
            evidence_type=EvidenceType.PATTERN,
            name="Conditional Update Validation",
            description="System compares user_update attributes with current_user's original "
                       "attributes. Only triggers check_username_is_taken or check_email_is_taken "
                       "when the values differ from existing ones.",
            description_cn="系统对比 user_update 传入的属性与 current_user 的原始属性。"
                          "仅当 user_update.username 或 user_update.email 与现有值不一致时，"
                          "才会触发 check_username_is_taken 或 check_email_is_taken 的查重逻辑。",
            location=self._create_code_location(func_data),
            related_elements=[
                "user_update",
                "current_user",
                "user_update.username",
                "user_update.email",
                "current_user.username",
                "current_user.email",
                "check_username_is_taken",
                "check_email_is_taken",
            ],
            metadata={
                "complexity": complexity,
                "parameters": [p.get("name") for p in parameters],
                "calls": calls,
                "has_user_update_param": has_user_update_param,
                "has_current_user_param": has_current_user_param,
                "has_conditional_logic": has_conditional_logic,
            }
        )
    
    def _extract_token_refresh_mechanism(self) -> List[CodeEvidence]:
        """
        Extract evidence for token refresh mechanism.
        
        Code Pattern:
        - Multiple functions call jwt.create_access_token_for_user
        - Returns token variable wrapped in UserWithToken
        - Covers login, register, retrieve_current_user, update_current_user
        """
        evidences = []
        
        for func_name, qualified_name in self.TARGET_FUNCTIONS.items():
            func_data = self._find_function(qualified_name)
            if not func_data:
                continue
            
            calls = func_data.get("calls", [])
            local_vars = func_data.get("local_variables", [])
            
            # Check for token generation pattern
            has_create_token = "jwt.create_access_token_for_user" in calls
            has_token_var = "token" in local_vars
            has_user_with_token = "UserWithToken" in calls
            
            if has_create_token and has_token_var:
                evidence = CodeEvidence(
                    evidence_id=f"DBR-01-TOKEN-{func_name.upper()}",
                    evidence_type=EvidenceType.CALL,
                    name=f"Token Refresh in {func_name}",
                    description=f"The {func_name} function calls jwt.create_access_token_for_user "
                               f"to generate token variable, wrapped in UserWithToken domain model.",
                    description_cn=f"函数 {func_name} 通过调用 jwt.create_access_token_for_user "
                                  f"生成 token 变量，并封装在 UserWithToken 领域模型中返回。",
                    location=self._create_code_location(func_data),
                    related_elements=[
                        "jwt.create_access_token_for_user",
                        "token",
                        "UserWithToken",
                        "UserInResponse",
                    ],
                    metadata={
                        "function_name": func_name,
                        "has_create_token": has_create_token,
                        "has_token_var": has_token_var,
                        "has_user_with_token": has_user_with_token,
                        "calls": calls,
                    }
                )
                evidences.append(evidence)
        
        return evidences
    
    def _extract_repository_atomicity(self) -> Optional[CodeEvidence]:
        """
        Extract evidence for repository storage atomicity.
        
        Code Pattern:
        - UsersRepository.create_user uses transaction
        - Password is hashed before persistence
        """
        # Find the UsersRepository class
        users_repo_module = self._find_module("app.db.repositories.users")
        if not users_repo_module:
            logger.warning("UsersRepository module not found")
            return None
        
        # Find create_user method
        create_user_data = self._find_function(self.REPOSITORY_METHODS["create_user"])
        if not create_user_data:
            logger.warning("create_user method not found")
            return None
        
        calls = create_user_data.get("calls", [])
        
        # Check for transaction and password hashing
        has_transaction = "self.connection.transaction" in calls
        has_password_change = "user.change_password" in calls
        has_create_query = "queries.create_new_user" in calls
        
        return CodeEvidence(
            evidence_id="DBR-01-REPO-ATOMICITY",
            evidence_type=EvidenceType.PATTERN,
            name="Repository Storage Atomicity",
            description="Account creation through UsersRepository ensures atomicity using "
                       "database transaction. Password is hashed via change_password before persistence.",
            description_cn="账户创建过程通过 UsersRepository 确保原子性，密码经哈希处理后持久化。"
                          "使用数据库事务保证操作的原子性。",
            location=self._create_code_location(create_user_data),
            related_elements=[
                "UsersRepository",
                "create_user",
                "change_password",
                "self.connection.transaction",
                "hashed_password",
                "salt",
            ],
            metadata={
                "has_transaction": has_transaction,
                "has_password_change": has_password_change,
                "has_create_query": has_create_query,
                "calls": calls,
            }
        )
    
    def _extract_uniqueness_service(self) -> List[CodeEvidence]:
        """
        Extract evidence for uniqueness check services.
        
        Code Pattern:
        - check_username_is_taken function
        - check_email_is_taken function
        - Both catch EntityDoesNotExist exception
        """
        evidences = []
        
        for service_name in ["check_username_is_taken", "check_email_is_taken"]:
            qualified_name = self.SERVICE_FUNCTIONS[service_name]
            func_data = self._find_function(qualified_name)
            if not func_data:
                continue
            
            calls = func_data.get("calls", [])
            
            evidence = CodeEvidence(
                evidence_id=f"DBR-01-SERVICE-{service_name.upper().replace('_', '-')}",
                evidence_type=EvidenceType.FUNCTION,
                name=f"Uniqueness Service: {service_name}",
                description=f"The {service_name} function queries the repository and catches "
                           f"EntityDoesNotExist to determine availability.",
                description_cn=f"函数 {service_name} 查询仓库并捕获 EntityDoesNotExist 异常来判断唯一性。",
                location=self._create_code_location(func_data),
                related_elements=[
                    service_name,
                    "EntityDoesNotExist",
                    "UsersRepository",
                ],
                metadata={
                    "calls": calls,
                    "return_type": func_data.get("return_type"),
                }
            )
            evidences.append(evidence)
        
        return evidences
    
    def generate_rule_metadata(self) -> Optional[RuleMetadata]:
        """Generate complete rule metadata for DBR-01."""
        if not self.analysis_data:
            if not self.load_analysis():
                return None
        
        # Extract all evidences
        login_exception = self._extract_login_exception_handling()
        register_precheck = self._extract_register_precheck()
        conditional_update = self._extract_conditional_update_check()
        token_evidences = self._extract_token_refresh_mechanism()
        repo_atomicity = self._extract_repository_atomicity()
        uniqueness_services = self._extract_uniqueness_service()
        
        # Create subcategories
        subcategories = []
        
        # Subcategory 1: Uniqueness Interception
        uniqueness_evidences = []
        if register_precheck:
            uniqueness_evidences.append(register_precheck)
        if conditional_update:
            uniqueness_evidences.append(conditional_update)
        uniqueness_evidences.extend(uniqueness_services)
        
        if uniqueness_evidences:
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-01",
                name="Multi-scenario Uniqueness Interception",
                name_cn="多场景唯一性拦截",
                description="System enforces uniqueness checks during user registration and profile "
                           "updates. If identifier is already taken, system explicitly intercepts "
                           "with 400 Bad Request.",
                description_cn="系统在用户注册及资料更新时，强制执行唯一性检查。"
                              "若标识符已被占用，系统通过 400 Bad Request 显式拦截。",
                evidences=uniqueness_evidences,
            ))
        
        # Subcategory 2: Account Security & Atomicity
        security_evidences = []
        if repo_atomicity:
            security_evidences.append(repo_atomicity)
        
        if security_evidences:
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-02",
                name="Account Security & Storage Atomicity",
                name_cn="账户安全性与存储原子性",
                description="Account creation process ensures atomicity through UsersRepository. "
                           "Password is hashed before persistence.",
                description_cn="账户创建过程通过 UsersRepository 确保原子性，密码经哈希处理后持久化。",
                evidences=security_evidences,
            ))
        
        # Subcategory 3: Authentication Security Feedback
        auth_feedback_evidences = []
        if login_exception:
            auth_feedback_evidences.append(login_exception)
        
        if auth_feedback_evidences:
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-03",
                name="Authentication Security Feedback",
                name_cn="身份验证安全反馈",
                description="Login uniformly catches exceptions and returns vague error message "
                           "INCORRECT_LOGIN_INPUT to prevent user enumeration attacks.",
                description_cn="登录时统一捕获异常，返回模糊错误信息 INCORRECT_LOGIN_INPUT，防止用户枚举。",
                evidences=auth_feedback_evidences,
            ))
        
        # Subcategory 4: Token Refresh Mechanism
        if token_evidences:
            subcategories.append(RuleSubCategory(
                subcategory_id="DBR-01-04",
                name="Dynamic Session State Maintenance",
                name_cn="动态会话状态维护",
                description="After successful operation, system regenerates and returns JWT token "
                           "to maintain client session state consistency.",
                description_cn="操作成功后重新生成并返回 JWT 令牌，维持客户端会话状态一致性。",
                evidences=token_evidences,
            ))
        
        # Collect all related files and functions
        related_files = set()
        related_functions = set()
        
        for subcat in subcategories:
            for evidence in subcat.evidences:
                related_files.add(evidence.location.file_path)
                if evidence.location.qualified_name:
                    related_functions.add(evidence.location.qualified_name)
        
        # Create the rule metadata
        rule_metadata = RuleMetadata(
            rule_id=self.RULE_ID,
            rule_name=self.RULE_NAME,
            rule_name_cn=self.RULE_NAME_CN,
            description="This rule ensures authentication and credential integrity through: "
                       "(1) Multi-scenario uniqueness interception during sign-up and update, "
                       "(2) Account security and storage atomicity with password hashing, "
                       "(3) Authentication security feedback with vague error messages, "
                       "(4) Dynamic session state maintenance via JWT token refresh.",
            description_cn="本规则通过以下机制确保身份准入与账户凭据完整性："
                          "（1）注册及更新时的多场景唯一性拦截；"
                          "（2）账户安全性与存储原子性（密码哈希）；"
                          "（3）身份验证安全反馈（模糊错误信息）；"
                          "（4）动态会话状态维护（JWT令牌刷新）。",
            version="1.0.0",
            created_at=datetime.now().isoformat(),
            analysis_source=str(self.analysis_json_path),
            project_name=self.analysis_data.get("project_name", "unknown"),
            subcategories=subcategories,
            related_files=sorted(related_files),
            related_functions=sorted(related_functions),
            dependencies=[
                "fastapi",
                "starlette",
                "jwt",
                "pydantic",
            ],
            tags=[
                "authentication",
                "security",
                "credential",
                "jwt",
                "user-management",
                "uniqueness-check",
                "password-hashing",
            ],
        )
        
        return rule_metadata


def convert_to_dict(obj: Any) -> Any:
    """Convert dataclass instances to dictionaries recursively."""
    if hasattr(obj, '__dataclass_fields__'):
        result = {}
        for k, v in asdict(obj).items():
            result[k] = convert_to_dict(v)
        return result
    elif isinstance(obj, list):
        return [convert_to_dict(item) for item in obj]
    elif isinstance(obj, dict):
        return {k: convert_to_dict(v) for k, v in obj.items()}
    elif isinstance(obj, Enum):
        return obj.value
    else:
        return obj


def generate_dbr01_metadata(
    analysis_json_path: str,
    output_path: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    """
    Generate DBR-01 rule metadata from AST analysis JSON.
    
    Args:
        analysis_json_path: Path to the AST analysis JSON file
        output_path: Optional path to save the rule metadata JSON
        
    Returns:
        Dictionary containing the rule metadata, or None if failed
    """
    mapper = DBR01RuleMapper(analysis_json_path)
    
    if not mapper.load_analysis():
        return None
    
    rule_metadata = mapper.generate_rule_metadata()
    if not rule_metadata:
        logger.error("Failed to generate rule metadata")
        return None
    
    # Convert to dictionary
    result = convert_to_dict(rule_metadata)
    
    # Save to file if output path provided
    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        logger.info(f"Rule metadata saved to: {output_path}")
    
    return result


def print_rule_summary(metadata: Dict[str, Any]) -> None:
    """Print a human-readable summary of the rule metadata."""
    print("\n" + "=" * 70)
    print(f"Rule Metadata Summary")
    print("=" * 70)
    
    print(f"\nRule ID: {metadata.get('rule_id')}")
    print(f"Rule Name: {metadata.get('rule_name')}")
    print(f"Rule Name (CN): {metadata.get('rule_name_cn')}")
    print(f"Version: {metadata.get('version')}")
    print(f"Created At: {metadata.get('created_at')}")
    print(f"Project: {metadata.get('project_name')}")
    
    print(f"\nDescription:")
    print(f"  {metadata.get('description')}")
    
    print(f"\n描述:")
    print(f"  {metadata.get('description_cn')}")
    
    print(f"\n--- Subcategories ({len(metadata.get('subcategories', []))}) ---")
    for i, subcat in enumerate(metadata.get('subcategories', []), 1):
        print(f"\n  {i}. {subcat.get('name')} ({subcat.get('subcategory_id')})")
        print(f"     {subcat.get('name_cn')}")
        print(f"     Evidences: {len(subcat.get('evidences', []))}")
        
        for evidence in subcat.get('evidences', []):
            print(f"       - [{evidence.get('evidence_type')}] {evidence.get('name')}")
            loc = evidence.get('location', {})
            print(f"         File: {loc.get('file_path')}:{loc.get('line_start')}-{loc.get('line_end')}")
    
    print(f"\n--- Related Files ({len(metadata.get('related_files', []))}) ---")
    for file_path in metadata.get('related_files', []):
        print(f"  - {file_path}")
    
    print(f"\n--- Tags ({len(metadata.get('tags', []))}) ---")
    print(f"  {', '.join(metadata.get('tags', []))}")
    
    print("\n" + "=" * 70)


def main():
    """Main entry point for the rule mapping generator."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='DBR-01 Rule Mapping Generator',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Generate rule metadata from analysis JSON
  python rule_mapping.py /path/to/analysis.json
  
  # Generate and save to specific output file
  python rule_mapping.py /path/to/analysis.json -o rule_metadata.json
  
  # Generate with summary output
  python rule_mapping.py /path/to/analysis.json --summary
        """
    )
    
    parser.add_argument(
        'analysis_path',
        nargs='?',
        default=None,
        help='Path to the AST analysis JSON file'
    )
    
    parser.add_argument(
        '-o', '--output',
        default=None,
        help='Output file path for rule metadata JSON'
    )
    
    parser.add_argument(
        '-s', '--summary',
        action='store_true',
        help='Print human-readable summary to console'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose logging'
    )
    
    args = parser.parse_args()
    
    # Configure logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Default paths
    script_dir = Path(__file__).parent.resolve()
    workspace_root = script_dir.parent.parent
    
    if args.analysis_path is None:
        args.analysis_path = workspace_root / 'data' / 'fastapi_analysis_result.json'
    
    if args.output is None:
        args.output = workspace_root / 'data' / 'dbr01_rule_metadata.json'
    
    # Verify analysis file exists
    analysis_path = Path(args.analysis_path)
    if not analysis_path.exists():
        print(f"Error: Analysis file not found: {analysis_path}")
        print("Please run fast_api_analyzer.py first to generate the analysis JSON.")
        return None
    
    # Generate rule metadata
    print(f"Reading analysis from: {analysis_path}")
    result = generate_dbr01_metadata(
        str(analysis_path),
        output_path=str(args.output) if args.output else None
    )
    
    if result:
        # Print summary if requested or by default when output is specified
        if args.summary or args.output:
            print_rule_summary(result)
        
        if args.output:
            print(f"\nRule metadata saved to: {args.output}")
        
        return result
    else:
        print("Failed to generate rule metadata")
        return None


if __name__ == '__main__':
    main()
